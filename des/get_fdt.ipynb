{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10d5ba8",
   "metadata": {},
   "source": [
    "# get_fdt test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157e1e2",
   "metadata": {},
   "source": [
    "## OJO - Revisar get_fdt() y Revisar el uso de las columnas de fdt en plt_pie y plt_pareto|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd12c3",
   "metadata": {},
   "source": [
    "## TO-DO\n",
    "- sort by values or by index\n",
    "- fmt_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38fb7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Libs\n",
    "from typing import Union, Optional, Literal, Any, Sequence, TypeAlias\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# Third-Party Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "IndexElement: TypeAlias = Union[str, int, float, pd.Timestamp]\n",
    "\n",
    "# # Local Libs\n",
    "# from jm_datascience import jm_pandas as jm_pd\n",
    "# from jm_datascience import jm_pdaccessor as jm\n",
    "# from jm_utils import jm_richprt as jm_prt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282540",
   "metadata": {},
   "source": [
    "## Some Series and DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4919c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work = pd.DataFrame({\n",
    "    'nombre': ['Ana', 'Bob', '', 'Carlos', ' ', 'Diana'],\n",
    "    'apellido': ['A_Ana', 'B_Bob', None, 'C_Carlos', None, 'D_Diana'],\n",
    "    'edad': [25, -1, 30, 999, 28, 22],\n",
    "    'ciudad': ['Madrid', 'N/A', 'Barcelona', 'Valencia', 'unknown', 'Sevilla'],\n",
    "    'salario': [50000, 0, 60000, -999, 55000, 48000]\n",
    "})\n",
    "\n",
    "## Read spreedsheet for tests\n",
    "try:\n",
    "    spreedsheet = r\"C:\\Users\\jm\\Documents\\__Dev\\PortableGit\\__localrepos\\365DS_jm\\3_statistics\\2_13_Practical_Ex_Descriptive_Stats.xlsx\"    # Casa\n",
    "    with open(spreedsheet) as f:\n",
    "        pass\n",
    "except FileNotFoundError:\n",
    "    spreedsheet = r\"D:\\git\\PortableGit\\__localrepos\\365DS_jm\\3_statistics\\2_13_Practical_Ex_Descriptive_Stats.xlsx\"                         # Office\n",
    "\n",
    "df_xls = pd.read_excel(spreedsheet, skiprows=4, usecols='B:J,L:AA', index_col='ID')\n",
    "df = df_xls.copy()\n",
    "\n",
    "lst_str = random.choices([chr(i) for i in range(65, 72)], k=175)\n",
    "# sr_str = jm_pd.to_series(lst_str)                         # <- jm_pd.to_serie_with_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9cee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Virginia', 'Arizona', 'Oregon', 'Nevada',\n",
       "       'Colorado', 'Utah', nan, 'Kansas', 'Wyoming'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Germany      1\n",
       "Mexico       1\n",
       "Denmark      1\n",
       "UK           2\n",
       "Belgium      2\n",
       "Russia       4\n",
       "Canada       7\n",
       "USA         12\n",
       "NaN         72\n",
       "USA        165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df['State'].unique())\n",
    "df['State'].value_counts(sort=False, ascending=True)\n",
    "df['Country'].value_counts(sort=True, ascending=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad6c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fmt_value_for_pd(value, width=8, decimals=3, miles=',') -> str:\n",
    "    \"\"\"\n",
    "    Format a value (numeric or string) into a right-aligned string of fixed width.\n",
    "\n",
    "    Converts numeric values to formatted strings with thousands separators and\n",
    "    specified decimal places. Strings are padded to the same width for consistent alignment.\n",
    "\n",
    "    Parameters:\n",
    "        value (int, float, str): The value to be formatted.\n",
    "        width (int): Total width of the output string. Must be a positive integer.\n",
    "        decimals (int): Number of decimal places for numeric values. Must be >= 0.\n",
    "        miles (str or None): Thousands separator. Valid options: ',', '_', or None.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted string with right alignment.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If width <= 0, decimals < 0, or miles is invalid.\n",
    "\n",
    "    Examples:\n",
    "        >>> format_value(123456.789)\n",
    "        '123,456.79'\n",
    "        >>> format_value(\"text\", width=10)\n",
    "        '      text'\n",
    "        >>> format_value(9876, miles=None)\n",
    "        '    9876.00'\n",
    "    \"\"\"\n",
    "    # Parameter Value validation <- vamos a tener que analizar este tema por si es un list , etc,,\n",
    "    #   - En realidad acá tenemos que evaluar algo similar a jm_utils - fmt_values() FUTURE\n",
    "    # if not isinstance(value, (int, float, np.integer, np.floating)) or pd.api.types.is_any_real_numeric_dtype(value)\n",
    "\n",
    "    if not isinstance(width, int) or width <= 0:\n",
    "        raise ValueError(f\"Width must be a positive integer. Not '{width}'\")\n",
    "    \n",
    "    if not isinstance(decimals, int) or decimals < 0:\n",
    "        raise ValueError(f\"Decimals must be a non-negative integer. Not '{decimals}\")\n",
    "    \n",
    "    if miles not in [',', '_', None]:\n",
    "        raise ValueError(f\"Miles must be either ',', '_', or None. Not '{miles}\")\n",
    "    \n",
    "    try:\n",
    "        num = float(value)                                  # Convert to float if possible\n",
    "        if num % 1 == 0:                                    # it its a total integer number\n",
    "            decimals = 0\n",
    "        if miles:\n",
    "            return f\"{num:>{width}{miles}.{decimals}f}\"     # Ancho fijo, x decimales, alineado a la derecha\n",
    "        else:\n",
    "            return f\"{num:>{width}.{decimals}f}\"\n",
    "        \n",
    "    except (ValueError, TypeError):\n",
    "        return str(value).rjust(width)                      # Alinea también strings, para mantener la grilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe510044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_series(\n",
    "    data: Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame],\n",
    "    index: Optional[Union[pd.Index, Sequence[IndexElement]]] = None,\n",
    "    name: Optional[str] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Converts input data into a pandas Series with optional custom index and name.\n",
    "\n",
    "    This function standardizes various data types into a pandas Series. It supports\n",
    "    arrays, dictionaries, lists, sets, DataFrames, and existing Series. Optionally,\n",
    "    a custom index or series name can be assigned.\n",
    "\n",
    "    Parameters:\n",
    "        data (Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame]):\n",
    "            Input data to convert. Supported types:\n",
    "            - pd.Series: returned as-is (can be overridden with new index/name).\n",
    "            - np.ndarray: flattened and converted to a Series.\n",
    "            - dict: keys become the index, values become the data.\n",
    "            - list or set: converted to a Series with default integer index.\n",
    "            - pd.DataFrame:\n",
    "                - 1 column: converted directly to a Series.\n",
    "                - 2 columns: first column becomes the index, second becomes the values.\n",
    "        index (Union[pd.Index, Sequence], optional): Custom index to assign to the Series.\n",
    "            If provided, overrides the original index. Default is None.\n",
    "        name (str, optional): Name to assign to the Series. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A pandas Series constructed from the input data, with optional\n",
    "            custom index and name.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the input data type is not supported.\n",
    "        ValueError: If the DataFrame has more than 2 columns.\n",
    "\n",
    "    Examples:\n",
    "        >>> import pandas as pd\n",
    "        >>> to_series([1, 2, 3, 4])\n",
    "        0    1\n",
    "        1    2\n",
    "        2    3\n",
    "        3    4\n",
    "        dtype: int64\n",
    "\n",
    "        >>> to_series({'A': 10, 'B': 20, 'C': 30})\n",
    "        A    10\n",
    "        B    20\n",
    "        C    30\n",
    "        dtype: int64\n",
    "\n",
    "        >>> df = pd.DataFrame({'Label': ['X', 'Y'], 'Value': [100, 200]})\n",
    "        >>> to_series(df)\n",
    "        Label\n",
    "        X    100\n",
    "        Y    200\n",
    "        Name: Value, dtype: int64\n",
    "\n",
    "        >>> to_series([10, 20, 30], index=['a', 'b', 'c'], name='Measurements')\n",
    "        a    10\n",
    "        b    20\n",
    "        c    30\n",
    "        Name: Measurements, dtype: int64\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate parameters - FUTURE\n",
    "    \n",
    "    if isinstance(data, pd.Series):                 # If series is already a Series no conversion needed\n",
    "        series = data                                  \n",
    "    elif isinstance(data, np.ndarray):              # If data is a NumPy array   \n",
    "        series = pd.Series(data.flatten())\n",
    "    elif isinstance(data, (dict, list)):\n",
    "        series = pd.Series(data)\n",
    "    elif isinstance(data, (set)):\n",
    "        series = pd.Series(list(data))\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        if data.shape[1] == 1:                      # Also len(data.columns == 1)\n",
    "            series = data.iloc[:, 0]\n",
    "        elif data.shape[1] == 2:                    # Index: first col, Data: 2nd Col\n",
    "            series = data.set_index(data.columns[0])[data.columns[1]]\n",
    "        else:\n",
    "            raise ValueError(\"DataFrame must have 1 oer 2 columns. Categories and values for 2 columns cases.\")\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported data type: {type(data)}. \"\n",
    "                    \"Supported types: pd.Series, np.ndarray, pd.DataFrame, dict, list, set, and pd.DataFrame\")\n",
    "\n",
    "    if name:\n",
    "        series.name = name\n",
    "\n",
    "    if index:\n",
    "        series.index = index\n",
    "\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389faabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_numeric_series(\n",
    "        data: Union[pd.Series, pd.DataFrame],\n",
    "        positive: Optional[bool] = True\n",
    ") -> Union[None, Exception]:\n",
    "\n",
    "    # Validate data parameter a pandas object\n",
    "    if not isinstance(data, (pd.Series, pd.DataFrame)):     # pd.Series or pd.Datafram\n",
    "        raise TypeError(\n",
    "            f\"Input data must be a pandas Series or DataFrame. Got {type(data)} instead.\"\n",
    "        )\n",
    "              \n",
    "    if positive:\n",
    "        if not all(                                             # Only positve numeric values                 \n",
    "            isinstance(val, (int, float, np.integer, np.floating)) and val > 0 for val in data.values\n",
    "        ):\n",
    "            raise ValueError(f\"All values in 'data' must be positive numeric values.\")\n",
    "        pass\n",
    "    else:                                                       # Just only numeric values\n",
    "        if not all(isinstance(val, (int, float, np.integer, np.floating)) for val in data.values):\n",
    "            raise ValueError(f\"All values in 'data' must be numeric values.\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6798e",
   "metadata": {},
   "source": [
    "## get_fdt() - Last Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71382b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdt3(\n",
    "        data: Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame],\n",
    "        value_counts: Optional[bool] = False,\n",
    "        dropna: Optional[bool] = True,\n",
    "        na_position: Optional[str] = 'last',\n",
    "        include_pcts: Optional[bool] = True,\n",
    "        include_flat_relatives: Optional[bool] = True,\n",
    "        fmt_values: Optional[bool] = False,\n",
    "        order: Optional[str] = 'desc',\n",
    "        na_aside_calc: Optional[bool] = True,\n",
    "        index_name: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a Frequency Distribution Table (FDT) with absolute, relative, and cumulative frequencies.\n",
    "\n",
    "    This function converts various input data types into a structured DataFrame containing:\n",
    "    - Absolute frequencies\n",
    "    - Cumulative frequencies\n",
    "    - Relative frequencies (proportions and percentages)\n",
    "    - Cumulative relative frequencies (percentages)\n",
    "\n",
    "    Parameters:\n",
    "        data (Union[pd.Series, np.ndarray, dict, list, pd.DataFrame]): Input data.\n",
    "            If DataFrame, it will be converted to a Series using `to_series`.\n",
    "        value_counts (bool, optional): Whether to count occurrences if input is raw data.\n",
    "            Assumes data is not pre-counted. Default is False.\n",
    "        dropna (bool, optional): Whether to exclude NaN values when counting frequencies.\n",
    "            Default is True.\n",
    "        na_position (str, optional): Position of NaN values in the output:\n",
    "            - 'first': Place NaN at the top.\n",
    "            - 'last': Place NaN at the bottom (default).\n",
    "            - 'value': Keep NaN in its natural order.\n",
    "            Default is 'last'.\n",
    "        include_pcts (bool, optional): Whether to include percentage columns.\n",
    "            If False, only absolute and cumulative frequencies are returned.\n",
    "            Default is True.\n",
    "        include_flat_relatives (bool, optional): Whether to return relative and cumulative relative values.\n",
    "            If False, only frequency and percentage columns are included.\n",
    "            Default is True.\n",
    "        fmt_values (bool, optional): Whether to format numeric values using `_fmt_value_for_pd`.\n",
    "            Useful for improving readability in reports. Default is False.\n",
    "        order (str, optional): Sort order for the output:\n",
    "            - 'asc': Sort values ascending.\n",
    "            - 'desc': Sort values descending (default).\n",
    "            - 'ix_asc': Sort by index ascending.\n",
    "            - 'ix_desc': Sort by index descending.\n",
    "            - None: No sorting.\n",
    "            Default is 'desc'.\n",
    "        na_aside_calc (bool, optional): Whether to separate NaN values from calculations but keep them in the output.\n",
    "            If True, NaNs are added at the end and not included in cumulative or relative calculations.\n",
    "            Default is True.\n",
    "        index_name (str, optional): Set an specific index name for the fdt.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the frequency distribution table with the following columns\n",
    "        (depending on parameters):\n",
    "            - Frequency\n",
    "            - Cumulative Frequency\n",
    "            - Relative Frequency\n",
    "            - Cumulative Relative Freq.\n",
    "            - Relative Freq. [%]\n",
    "            - Cumulative Freq. [%]\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `sort` or `na_position` receive invalid values.\n",
    "\n",
    "    Notes:\n",
    "        - This function uses `to_series` to convert input data into a pandas Series.\n",
    "        - If `na_aside=True` and NaNs are present, they are placed separately and not included in relative calculations.\n",
    "        - Useful for exploratory data analysis and generating clean statistical summaries.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> data = pd.Series(['A', 'B', 'A', 'C', 'B', 'B', None])\n",
    "        >>> fdt = get_fdt(data, sort='desc', fmt_values=True)\n",
    "        >>> print(fdt)\n",
    "              Frequency  Cumulative Frequency  Relative Freq. [%]  Cumulative Freq. [%]\n",
    "        B           3                   3                42.86                  42.86\n",
    "        A           2                   5                28.57                  71.43\n",
    "        C           1                   6                14.29                  85.71\n",
    "        Nulls       1                   7                14.29                 100.00\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        'Frequency',\n",
    "        'Cumulative Frequency',\n",
    "        'Relative Frequency',\n",
    "        'Cumulative Relative Freq.',\n",
    "        'Relative Freq. [%]',\n",
    "        'Cumulative Freq. [%]'\n",
    "    ]\n",
    "    # def _calculate_fdt_relatives(series):     # Revisar, no me gusta el flujo actual\n",
    "    \n",
    "    sr = to_series(data)\n",
    "    \n",
    "    if dropna:\n",
    "        sr = sr.dropna()                        # Drop all nulls values of the Series\n",
    "        sr = sr.drop(np.nan, errors='ignore')   # For series with NaNs as a category with their count (errors='ignore': does not fail if it does not exist)\n",
    "\n",
    "    if value_counts:\n",
    "        sr = sr.value_counts(dropna=dropna, sort=False)\n",
    "\n",
    "    # Validate that all the values are positive numbers\n",
    "    _validate_numeric_series(sr)\n",
    "\n",
    "    # Order de original Series to obtain the fdt in the same order as the original data\n",
    "    match order:\n",
    "        case 'asc':\n",
    "            sr = sr.sort_values()\n",
    "        case 'desc':\n",
    "            sr = sr.sort_values(ascending=False)\n",
    "        case 'ix_asc':\n",
    "            sr = sr.sort_index()\n",
    "        case 'ix_desc':\n",
    "            sr = sr.sort_index(ascending=False)\n",
    "        case None:\n",
    "            pass\n",
    "        case _:\n",
    "            raise ValueError(f\"Valid values for order: 'asc', 'desc', 'ix_asc', 'ix_desc', or None. Got '{order}'\")\n",
    "        \n",
    "    # Handle NaNs values. Two cases: 1. na_aside: don't use for calcs and at the end; 2. use for calcs and locate according na_position\n",
    "    #   - Determine the number of nans\n",
    "    if pd.isna(sr.index).any():\n",
    "        n_nans = sr[np.nan]\n",
    "    else:\n",
    "        n_nans = 0\n",
    "\n",
    "    #   - Locale NaNs row in the Series 'sr'\n",
    "    if na_aside_calc:\n",
    "        sr = sr.drop(np.nan, errors='ignore')                   # Drop NaNs from the Series for calculations\n",
    "        # Column that will then be concatenated to the end of the DF - Only 'Frequency' column, no calculated columns\n",
    "        nan_row_df = pd.DataFrame(data = [n_nans], columns=[columns[0]], index=[np.nan])\n",
    "    else:\n",
    "        # As we use NaNs for calculations decide where locate these values\n",
    "        sr_without_nan = sr.drop(np.nan, errors='ignore')       # Aux. sr wo/nans allow us to locate the NaNs\n",
    "        match na_position:             \n",
    "            case 'first':\n",
    "                sr = pd.concat([pd.Series({np.nan: n_nans}), sr_without_nan])\n",
    "            case 'last':\n",
    "                sr = pd.concat([sr_without_nan, pd.Series({np.nan: n_nans})])\n",
    "            case 'value' | None:\n",
    "                pass                # Locates the Nulls row based on the value or index ordering\n",
    "            case _:\n",
    "                raise ValueError(f\"Valid values for na_position: 'first', 'last', 'value' or None. Got '{na_position}'\")\n",
    "\n",
    "    # Central rutine: create the fdt, including relative and cumulative columns.\n",
    "    fdt = pd.DataFrame(sr)\n",
    "    fdt.columns = [columns[0]]\n",
    "    fdt[columns[1]] = fdt['Frequency'].cumsum()\n",
    "    fdt[columns[2]] = fdt['Frequency'] / fdt['Frequency'].sum()\n",
    "    fdt[columns[3]] = fdt['Relative Frequency'].cumsum()\n",
    "    fdt[columns[4]] = fdt['Relative Frequency'] * 100\n",
    "    fdt[columns[5]] = fdt['Cumulative Relative Freq.'] * 100\n",
    "\n",
    "    if na_aside_calc and not dropna:            # We add nan_columns at the end\n",
    "        fdt = pd.concat([fdt, nan_row_df])\n",
    "\n",
    "    # Logic to include: only frequencies, or only flat relatives, or percentage (pcts)\n",
    "    if not include_pcts and not include_flat_relatives:\n",
    "        fdt = fdt[[columns[0]]]                             # Only 'Frecquency' (col[0]) - doble[[]] to get a DF\n",
    "    elif not include_pcts and include_flat_relatives:\n",
    "        fdt = fdt[columns[0:4]]                             # 'Frequency' + plain_relative cols (col[0,1,2,3])\n",
    "    elif include_pcts and not include_pcts:\n",
    "        fdt = fdt[[columns[0], columns[4], columns[5]]]     # 'Frequency' + pcts cols (last two cols)\n",
    "\n",
    "    if fmt_values:\n",
    "        fdt = fdt.map(_fmt_value_for_pd)\n",
    "\n",
    "    # Set the index name\n",
    "    fdt.index.name = index_name if index_name else sr.index.name\n",
    "        \n",
    "    return fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5efe531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603 SW</th>\n",
       "      <td>21</td>\n",
       "      <td>No POE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608 SW</th>\n",
       "      <td>6</td>\n",
       "      <td>Headset compatible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616 SW</th>\n",
       "      <td>3</td>\n",
       "      <td>Telefonista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611 G</th>\n",
       "      <td>8</td>\n",
       "      <td>Gerencial Gigabit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Stock                 Obs\n",
       "1603 SW     21              No POE\n",
       "1608 SW      6  Headset compatible\n",
       "1616 SW      3         Telefonista\n",
       "9611 G       8   Gerencial Gigabit"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Para resolver el tema del index_name cuando no hay value counts\n",
    "# Data\n",
    "dic = {'1603 SW': [21, 'No POE'], '1608 SW': [6, 'Headset compatible'], \n",
    "       '1616 SW': [3, 'Telefonista'], '9611 G': [8, 'Gerencial Gigabit']}\n",
    "df = pd.DataFrame.from_dict(dic, orient='index', columns=['Stock', 'Obs'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6875d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1603 SW</th>\n",
       "      <th>1608 SW</th>\n",
       "      <th>1616 SW</th>\n",
       "      <th>9611 G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No POE</td>\n",
       "      <td>Headset compatible</td>\n",
       "      <td>Telefonista</td>\n",
       "      <td>Gerencial Gigabit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  1603 SW             1608 SW      1616 SW             9611 G\n",
       "0      21                   6            3                  8\n",
       "1  No POE  Headset compatible  Telefonista  Gerencial Gigabit"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Para resolver el tema del index_name cuando no hay value counts\n",
    "# Data\n",
    "df2 = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91775e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f591cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Cumulative Frequency</th>\n",
       "      <th>Relative Frequency</th>\n",
       "      <th>Cumulative Relative Freq.</th>\n",
       "      <th>Relative Freq. [%]</th>\n",
       "      <th>Cumulative Freq. [%]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Frequency  Cumulative Frequency  Relative Frequency  \\\n",
       "last3                                                        \n",
       "y             15                    15                0.75   \n",
       "z              3                    18                0.15   \n",
       "x              2                    20                0.10   \n",
       "\n",
       "       Cumulative Relative Freq.  Relative Freq. [%]  Cumulative Freq. [%]  \n",
       "last3                                                                       \n",
       "y                           0.75                75.0                  75.0  \n",
       "z                           0.90                15.0                  90.0  \n",
       "x                           1.00                10.0                 100.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = random.choices(['x', 'y', 'z'], weights=[1,4,1], k=20)\n",
    "sl1 = to_series(l1, name='last3')\n",
    "# sl1 = to_series(l1)\n",
    "# fdt = get_fdt3(sl1, value_counts=True, index_name='xyz')\n",
    "fdt = get_fdt3(sl1, value_counts=True)\n",
    "fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134e56d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Cumulative Frequency</th>\n",
       "      <th>Relative Frequency</th>\n",
       "      <th>Cumulative Relative Freq.</th>\n",
       "      <th>Relative Freq. [%]</th>\n",
       "      <th>Cumulative Freq. [%]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.657</td>\n",
       "      <td>65.746</td>\n",
       "      <td>65.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>17</td>\n",
       "      <td>136</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.751</td>\n",
       "      <td>9.392</td>\n",
       "      <td>75.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.812</td>\n",
       "      <td>6.077</td>\n",
       "      <td>81.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>11</td>\n",
       "      <td>158</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.873</td>\n",
       "      <td>6.077</td>\n",
       "      <td>87.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.934</td>\n",
       "      <td>6.077</td>\n",
       "      <td>93.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.967</td>\n",
       "      <td>3.315</td>\n",
       "      <td>96.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>4</td>\n",
       "      <td>179</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.989</td>\n",
       "      <td>2.210</td>\n",
       "      <td>98.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.552</td>\n",
       "      <td>99.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>86</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Frequency Cumulative Frequency Relative Frequency  \\\n",
       "State                                                          \n",
       "California       119                  119              0.657   \n",
       "Nevada            17                  136              0.094   \n",
       "Colorado          11                  147              0.061   \n",
       "Oregon            11                  158              0.061   \n",
       "Arizona           11                  169              0.061   \n",
       "Utah               6                  175              0.033   \n",
       "Virginia           4                  179              0.022   \n",
       "Kansas             1                  180              0.006   \n",
       "Wyoming            1                  181              0.006   \n",
       "NaN               86                  nan                nan   \n",
       "\n",
       "           Cumulative Relative Freq. Relative Freq. [%] Cumulative Freq. [%]  \n",
       "State                                                                         \n",
       "California                     0.657             65.746               65.746  \n",
       "Nevada                         0.751              9.392               75.138  \n",
       "Colorado                       0.812              6.077               81.215  \n",
       "Oregon                         0.873              6.077               87.293  \n",
       "Arizona                        0.934              6.077               93.370  \n",
       "Utah                           0.967              3.315               96.685  \n",
       "Virginia                       0.989              2.210               98.895  \n",
       "Kansas                         0.994              0.552               99.448  \n",
       "Wyoming                        1.000              0.552              100.000  \n",
       "NaN                              nan                nan                  nan  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdt = get_fdt3(df['State'], value_counts=True, dropna=False, fmt_values=True)\n",
    "fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2ad30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937a430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Frequency\n",
       "Gender          \n",
       "M            108\n",
       "F             70\n",
       "NaN           89"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdt = get_fdt3(df['Gender'], value_counts=True, dropna=False, fmt_values=True, include_flat_relatives=False, include_pcts=False)\n",
    "fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fc3025b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "M           108\n",
       "F            70\n",
       "NaN          89\n",
       "Name: Frequency, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = fdt.iloc[:, 0]\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0abce4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M           108\n",
       "F            70\n",
       "NaN          89\n",
       "Name: Frequency, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr1 = fdt['Frequency']\n",
    "sr1.index.name = None\n",
    "sr1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ebfc3",
   "metadata": {},
   "source": [
    "## OJO - podemos refactor get_fdt\n",
    "- Podemos impactar el 'order' directamente a la fdt resultante y no a la serie previa\n",
    "- De esta manera podemo hacer que el valor del aside también se ordene pero NOOO.. mejor que si es aside quede al final!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb7068fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdt0(\n",
    "        data: Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame],\n",
    "        value_counts: Optional[bool] = False,\n",
    "        dropna: Optional[bool] = True,\n",
    "        na_position: Optional[str] = 'last',\n",
    "        include_pcts: Optional[bool] = True,\n",
    "        include_plain_relatives: Optional[bool] = True,\n",
    "        fmt_values: Optional[bool] = False,\n",
    "        order: Optional[str] = 'desc',\n",
    "        na_aside: Optional[bool] = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a Frequency Distribution Table (FDT) with absolute, relative, and cumulative frequencies.\n",
    "\n",
    "    This function converts various input data types into a structured DataFrame containing:\n",
    "    - Absolute frequencies\n",
    "    - Cumulative frequencies\n",
    "    - Relative frequencies (proportions and percentages)\n",
    "    - Cumulative relative frequencies (percentages)\n",
    "\n",
    "    Parameters:\n",
    "        data (Union[pd.Series, np.ndarray, dict, list, pd.DataFrame]): Input data.\n",
    "            If DataFrame, it will be converted to a Series using `to_series`.\n",
    "        value_counts (bool, optional): Whether to count occurrences if input is raw data.\n",
    "            Assumes data is not pre-counted. Default is False.\n",
    "        dropna (bool, optional): Whether to exclude NaN values when counting frequencies.\n",
    "            Default is True.\n",
    "        na_position (str, optional): Position of NaN values in the output:\n",
    "            - 'first': Place NaN at the top.\n",
    "            - 'last': Place NaN at the bottom (default).\n",
    "            - 'value': Keep NaN in its natural order.\n",
    "            Default is 'last'.\n",
    "        include_pcts (bool, optional): Whether to include percentage columns.\n",
    "            If False, only absolute and cumulative frequencies are returned.\n",
    "            Default is True.\n",
    "        include_plain_relatives (bool, optional): Whether to return relative and cumulative relative values.\n",
    "            If False, only frequency and percentage columns are included.\n",
    "            Default is True.\n",
    "        fmt_values (bool, optional): Whether to format numeric values using `_fmt_value_for_pd`.\n",
    "            Useful for improving readability in reports. Default is False.\n",
    "        order (str, optional): Sort order for the output:\n",
    "            - 'asc': Sort values ascending.\n",
    "            - 'desc': Sort values descending (default).\n",
    "            - 'ix_asc': Sort by index ascending.\n",
    "            - 'ix_desc': Sort by index descending.\n",
    "            - None: No sorting.\n",
    "            Default is 'desc'.\n",
    "        na_aside (bool, optional): Whether to separate NaN values from calculations but keep them in the output.\n",
    "            If True, NaNs are added at the end and not included in cumulative or relative calculations.\n",
    "            Default is True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the frequency distribution table with the following columns\n",
    "        (depending on parameters):\n",
    "            - Frequency\n",
    "            - Cumulative Frequency\n",
    "            - Relative Frequency\n",
    "            - Cumulative Relative Freq.\n",
    "            - Relative Freq. [%]\n",
    "            - Cumulative Freq. [%]\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `sort` or `na_position` receive invalid values.\n",
    "\n",
    "    Notes:\n",
    "        - This function uses `to_series` to convert input data into a pandas Series.\n",
    "        - If `na_aside=True` and NaNs are present, they are placed separately and not included in relative calculations.\n",
    "        - Useful for exploratory data analysis and generating clean statistical summaries.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> data = pd.Series(['A', 'B', 'A', 'C', 'B', 'B', None])\n",
    "        >>> fdt = get_fdt(data, sort='desc', fmt_values=True)\n",
    "        >>> print(fdt)\n",
    "              Frequency  Cumulative Frequency  Relative Freq. [%]  Cumulative Freq. [%]\n",
    "        B           3                   3                42.86                  42.86\n",
    "        A           2                   5                28.57                  71.43\n",
    "        C           1                   6                14.29                  85.71\n",
    "        Nulls       1                   7                14.29                 100.00\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        'Frequency',\n",
    "        'Cumulative Frequency',\n",
    "        'Relative Frequency',\n",
    "        'Cumulative Relative Freq.',\n",
    "        'Relative Freq. [%]',\n",
    "        'Cumulative Freq. [%]'\n",
    "    ]\n",
    "    # def _calculate_fdt_relatives(series):     # Revisar, no me gusta el flujo actual\n",
    "    \n",
    "    sr = to_series(data)\n",
    "    \n",
    "    if dropna:\n",
    "        sr = sr.dropna()                        # Drop all nulls values of the Series\n",
    "        sr = sr.drop(np.nan, errors='ignore')   # For series with NaNs as a category with their count (errors='ignore': does not fail if it does not exist)\n",
    "\n",
    "    if value_counts:\n",
    "        sr = sr.value_counts(dropna=dropna, sort=False)\n",
    "\n",
    "    # Validate that all the values are positive numbers\n",
    "    if not _validate_numeric_series(sr):\n",
    "        raise ValueError(f\"To get a Frequency Distribution Table all frequencies must by positive numbers\")\n",
    "\n",
    "    # Order de original Series to obtain the fdt in the same order as the original data\n",
    "    match order:\n",
    "        case 'asc':\n",
    "            sr = sr.sort_values()\n",
    "        case 'desc':\n",
    "            sr = sr.sort_values(ascending=False)\n",
    "        case 'ix_asc':\n",
    "            sr = sr.sort_index()\n",
    "        case 'ix_desc':\n",
    "            sr = sr.sort_index(ascending=False)\n",
    "        case None:\n",
    "            pass\n",
    "        case _:\n",
    "            raise ValueError(f\"Valid values for order: 'asc', 'desc', 'ix_asc', 'ix_desc', or None. Got '{order}'\")\n",
    "\n",
    "    # Handle NaN values \n",
    "    try:                            # To manage when there aren't NaNs\n",
    "        nan_value = sr[np.nan]\n",
    "        sr_without_nan = sr.drop(np.nan)\n",
    "    except:\n",
    "        nan_value = 0\n",
    "        sr_without_nan = sr.copy()  # If no NaNs, we keep the original series without changes\n",
    "    finally:\n",
    "        if na_aside:\n",
    "            # Column that will then be concatenated to the end of the DF if the na_aside option is true\n",
    "            nan_row_df = pd.DataFrame(data = [nan_value], columns=[columns[0]], index=['Nulls'])      # Only 'Frequency' column.\n",
    "            if nan_value > 0:\n",
    "                sr = sr_without_nan\n",
    "\n",
    "    match na_position and not na_aside:              # Locate the NaNs values\n",
    "        case 'first':\n",
    "            sr = pd.concat([pd.Series({np.nan: nan_value}), sr_without_nan])\n",
    "        case 'last':\n",
    "            sr = pd.concat([sr_without_nan, pd.Series({np.nan: nan_value})])\n",
    "        case 'value' | None:\n",
    "            pass\n",
    "        case _:\n",
    "            raise ValueError(f\"Valid values for na_position: 'first', 'last', 'value' or None. Got '{na_position}'\")\n",
    "\n",
    "    # Central rutine: create the fdt, including relative and cumulative columns.\n",
    "    fdt = pd.DataFrame(sr)\n",
    "    fdt.columns = [columns[0]]\n",
    "    fdt[columns[1]] = fdt['Frequency'].cumsum()\n",
    "    fdt[columns[2]] = fdt['Frequency'] / fdt['Frequency'].sum()\n",
    "    fdt[columns[3]] = fdt['Relative Frequency'].cumsum()\n",
    "    fdt[columns[4]] = fdt['Relative Frequency'] * 100\n",
    "    fdt[columns[5]] = fdt['Cumulative Relative Freq.'] * 100\n",
    "\n",
    "    if na_aside and not dropna:             # We add nan_columns at the end\n",
    "        fdt = pd.concat([fdt, nan_row_df])\n",
    "\n",
    "    if not include_pcts:                    # Don't return percentage columns\n",
    "        fdt = fdt[columns[0:4]]\n",
    "    \n",
    "    if not include_plain_relatives:         # Don't return relative and plain cumulative\n",
    "        fdt = fdt[[columns[0], columns[4], columns[5]]]\n",
    "\n",
    "    if fmt_values:\n",
    "        fdt = fdt.map(_fmt_value_for_pd)\n",
    "        \n",
    "    return fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32acf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdt(\n",
    "        data: Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame],\n",
    "        value_counts: Optional[bool] = False,\n",
    "        dropna: Optional[bool] = True,\n",
    "        na_position: Optional[str] = 'last',\n",
    "        include_pcts: Optional[bool] = True,\n",
    "        include_plain_relatives: Optional[bool] = True,\n",
    "        fmt_values: Optional[bool] = False,\n",
    "        order: Optional[str] = 'desc',\n",
    "        na_aside_calc: Optional[bool] = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a Frequency Distribution Table (FDT) with absolute, relative, and cumulative frequencies.\n",
    "\n",
    "    This function converts various input data types into a structured DataFrame containing:\n",
    "    - Absolute frequencies\n",
    "    - Cumulative frequencies\n",
    "    - Relative frequencies (proportions and percentages)\n",
    "    - Cumulative relative frequencies (percentages)\n",
    "\n",
    "    Parameters:\n",
    "        data (Union[pd.Series, np.ndarray, dict, list, pd.DataFrame]): Input data.\n",
    "            If DataFrame, it will be converted to a Series using `to_series`.\n",
    "        value_counts (bool, optional): Whether to count occurrences if input is raw data.\n",
    "            Assumes data is not pre-counted. Default is False.\n",
    "        dropna (bool, optional): Whether to exclude NaN values when counting frequencies.\n",
    "            Default is True.\n",
    "        na_position (str, optional): Position of NaN values in the output:\n",
    "            - 'first': Place NaN at the top.\n",
    "            - 'last': Place NaN at the bottom (default).\n",
    "            - 'value': Keep NaN in its natural order.\n",
    "            Default is 'last'.\n",
    "        include_pcts (bool, optional): Whether to include percentage columns.\n",
    "            If False, only absolute and cumulative frequencies are returned.\n",
    "            Default is True.\n",
    "        include_plain_relatives (bool, optional): Whether to return relative and cumulative relative values.\n",
    "            If False, only frequency and percentage columns are included.\n",
    "            Default is True.\n",
    "        fmt_values (bool, optional): Whether to format numeric values using `_fmt_value_for_pd`.\n",
    "            Useful for improving readability in reports. Default is False.\n",
    "        order (str, optional): Sort order for the output:\n",
    "            - 'asc': Sort values ascending.\n",
    "            - 'desc': Sort values descending (default).\n",
    "            - 'ix_asc': Sort by index ascending.\n",
    "            - 'ix_desc': Sort by index descending.\n",
    "            - None: No sorting.\n",
    "            Default is 'desc'.\n",
    "        na_aside_calc (bool, optional): Whether to separate NaN values from calculations but keep them in the output.\n",
    "            If True, NaNs are added at the end and not included in cumulative or relative calculations.\n",
    "            Default is True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the frequency distribution table with the following columns\n",
    "        (depending on parameters):\n",
    "            - Frequency\n",
    "            - Cumulative Frequency\n",
    "            - Relative Frequency\n",
    "            - Cumulative Relative Freq.\n",
    "            - Relative Freq. [%]\n",
    "            - Cumulative Freq. [%]\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `sort` or `na_position` receive invalid values.\n",
    "\n",
    "    Notes:\n",
    "        - This function uses `to_series` to convert input data into a pandas Series.\n",
    "        - If `na_aside=True` and NaNs are present, they are placed separately and not included in relative calculations.\n",
    "        - Useful for exploratory data analysis and generating clean statistical summaries.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> data = pd.Series(['A', 'B', 'A', 'C', 'B', 'B', None])\n",
    "        >>> fdt = get_fdt(data, sort='desc', fmt_values=True)\n",
    "        >>> print(fdt)\n",
    "              Frequency  Cumulative Frequency  Relative Freq. [%]  Cumulative Freq. [%]\n",
    "        B           3                   3                42.86                  42.86\n",
    "        A           2                   5                28.57                  71.43\n",
    "        C           1                   6                14.29                  85.71\n",
    "        Nulls       1                   7                14.29                 100.00\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        'Frequency',\n",
    "        'Cumulative Frequency',\n",
    "        'Relative Frequency',\n",
    "        'Cumulative Relative Freq.',\n",
    "        'Relative Freq. [%]',\n",
    "        'Cumulative Freq. [%]'\n",
    "    ]\n",
    "    # def _calculate_fdt_relatives(series):     # Revisar, no me gusta el flujo actual\n",
    "    \n",
    "    sr = to_series(data)\n",
    "    \n",
    "    if dropna:\n",
    "        sr = sr.dropna()                        # Drop all nulls values of the Series\n",
    "        sr = sr.drop(np.nan, errors='ignore')   # For series with NaNs as a category with their count (errors='ignore': does not fail if it does not exist)\n",
    "\n",
    "    if value_counts:\n",
    "        sr = sr.value_counts(dropna=dropna, sort=False)\n",
    "\n",
    "    # Validate that all the values are positive numbers\n",
    "    _validate_numeric_series(sr)\n",
    "\n",
    "    # Get the index name or use 'Index' if None - will use it later to set the index name in concat cases\n",
    "    sr_ixname = sr.index.name if sr.index.name else 'Index'\n",
    "\n",
    "    # Order de original Series to obtain the fdt in the same order as the original data\n",
    "    match order:\n",
    "        case 'asc':\n",
    "            sr = sr.sort_values()\n",
    "        case 'desc':\n",
    "            sr = sr.sort_values(ascending=False)\n",
    "        case 'ix_asc':\n",
    "            sr = sr.sort_index()\n",
    "        case 'ix_desc':\n",
    "            sr = sr.sort_index(ascending=False)\n",
    "        case None:\n",
    "            pass\n",
    "        case _:\n",
    "            raise ValueError(f\"Valid values for order: 'asc', 'desc', 'ix_asc', 'ix_desc', or None. Got '{order}'\")\n",
    "        \n",
    "    # Handle NaNs values. Two cases: 1. na_aside: don't use for calcs and at the end; 2. use for calcs and locate according na_position\n",
    "    #   - Determine the number of nans\n",
    "    if pd.isna(sr.index).any():\n",
    "        n_nans = sr[np.nan]\n",
    "    else:\n",
    "        n_nans = 0\n",
    "\n",
    "    #   - Locale NaNs row in the Series 'sr'\n",
    "    if na_aside_calc:\n",
    "        sr = sr.drop(np.nan, errors='ignore')                   # Drop NaNs from the Series for calculations\n",
    "        # Column that will then be concatenated to the end of the DF - Only 'Frequency' column, no calculated columns\n",
    "        nan_row_df = pd.DataFrame(data = [n_nans], columns=[columns[0]], index=[np.nan])\n",
    "    else:\n",
    "        # As we use NaNs for calculations decide where locate these values\n",
    "        sr_without_nan = sr.drop(np.nan, errors='ignore')       # Aux. sr wo/nans allow us to locate the NaNs\n",
    "        match na_position:             \n",
    "            case 'first':\n",
    "                sr = pd.concat([pd.Series({np.nan: n_nans}), sr_without_nan])\n",
    "                sr.index.name = sr_ixname       # Set the index name to the Series\n",
    "            case 'last':\n",
    "                sr = pd.concat([sr_without_nan, pd.Series({np.nan: n_nans})])\n",
    "                sr.index.name = sr_ixname       # Set the index name to the Series\n",
    "            case 'value' | None:\n",
    "                pass                # Locates the Nulls row based on the value or index ordering\n",
    "            case _:\n",
    "                raise ValueError(f\"Valid values for na_position: 'first', 'last', 'value' or None. Got '{na_position}'\")\n",
    "\n",
    "    # Central rutine: create the fdt, including relative and cumulative columns.\n",
    "    fdt = pd.DataFrame(sr)\n",
    "    fdt.columns = [columns[0]]\n",
    "    fdt[columns[1]] = fdt['Frequency'].cumsum()\n",
    "    fdt[columns[2]] = fdt['Frequency'] / fdt['Frequency'].sum()\n",
    "    fdt[columns[3]] = fdt['Relative Frequency'].cumsum()\n",
    "    fdt[columns[4]] = fdt['Relative Frequency'] * 100\n",
    "    fdt[columns[5]] = fdt['Cumulative Relative Freq.'] * 100\n",
    "\n",
    "    if na_aside_calc and not dropna:            # We add nan_columns at the end\n",
    "        fdt = pd.concat([fdt, nan_row_df])\n",
    "        fdt.index.name = sr_ixname              # Set the index name to the DataFrame\n",
    "\n",
    "    if not include_pcts:                        # Don't return percentage columns\n",
    "        fdt = fdt[columns[0:4]]\n",
    "    \n",
    "    if not include_plain_relatives:             # Don't return relative and plain cumulative\n",
    "        fdt = fdt[[columns[0], columns[4], columns[5]]]\n",
    "\n",
    "    if fmt_values:\n",
    "        fdt = fdt.map(_fmt_value_for_pd)\n",
    "        \n",
    "    return fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a57cbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Cumulative Frequency</th>\n",
       "      <th>Relative Frequency</th>\n",
       "      <th>Cumulative Relative Freq.</th>\n",
       "      <th>Relative Freq. [%]</th>\n",
       "      <th>Cumulative Freq. [%]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.061</td>\n",
       "      <td>6.077</td>\n",
       "      <td>6.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>119</td>\n",
       "      <td>130</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.718</td>\n",
       "      <td>65.746</td>\n",
       "      <td>71.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>11</td>\n",
       "      <td>141</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.779</td>\n",
       "      <td>6.077</td>\n",
       "      <td>77.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.552</td>\n",
       "      <td>78.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>17</td>\n",
       "      <td>159</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.878</td>\n",
       "      <td>9.392</td>\n",
       "      <td>87.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.939</td>\n",
       "      <td>6.077</td>\n",
       "      <td>93.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3.315</td>\n",
       "      <td>97.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.994</td>\n",
       "      <td>2.210</td>\n",
       "      <td>99.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Frequency Cumulative Frequency Relative Frequency  \\\n",
       "State                                                          \n",
       "Arizona           11                   11              0.061   \n",
       "California       119                  130              0.657   \n",
       "Colorado          11                  141              0.061   \n",
       "Kansas             1                  142              0.006   \n",
       "Nevada            17                  159              0.094   \n",
       "Oregon            11                  170              0.061   \n",
       "Utah               6                  176              0.033   \n",
       "Virginia           4                  180              0.022   \n",
       "Wyoming            1                  181              0.006   \n",
       "NaN                0                  nan                nan   \n",
       "\n",
       "           Cumulative Relative Freq. Relative Freq. [%] Cumulative Freq. [%]  \n",
       "State                                                                         \n",
       "Arizona                        0.061              6.077                6.077  \n",
       "California                     0.718             65.746               71.823  \n",
       "Colorado                       0.779              6.077               77.901  \n",
       "Kansas                         0.785              0.552               78.453  \n",
       "Nevada                         0.878              9.392               87.845  \n",
       "Oregon                         0.939              6.077               93.923  \n",
       "Utah                           0.972              3.315               97.238  \n",
       "Virginia                       0.994              2.210               99.448  \n",
       "Wyoming                        1.000              0.552              100.000  \n",
       "NaN                              nan                nan                  nan  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = df['State'].value_counts()\n",
    "fdt = get_fdt(vc, fmt_values=True, dropna=False, na_position='value', na_aside_calc=True, order='ix_asc')\n",
    "fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbca1ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Cumulative Frequency</th>\n",
       "      <th>Relative Frequency</th>\n",
       "      <th>Cumulative Relative Freq.</th>\n",
       "      <th>Relative Freq. [%]</th>\n",
       "      <th>Cumulative Freq. [%]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.061</td>\n",
       "      <td>6.077</td>\n",
       "      <td>6.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>119</td>\n",
       "      <td>130</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.718</td>\n",
       "      <td>65.746</td>\n",
       "      <td>71.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>11</td>\n",
       "      <td>141</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.779</td>\n",
       "      <td>6.077</td>\n",
       "      <td>77.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.552</td>\n",
       "      <td>78.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>17</td>\n",
       "      <td>159</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.878</td>\n",
       "      <td>9.392</td>\n",
       "      <td>87.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.939</td>\n",
       "      <td>6.077</td>\n",
       "      <td>93.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.972</td>\n",
       "      <td>3.315</td>\n",
       "      <td>97.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.994</td>\n",
       "      <td>2.210</td>\n",
       "      <td>99.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>86</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Frequency Cumulative Frequency Relative Frequency  \\\n",
       "State                                                          \n",
       "Arizona           11                   11              0.061   \n",
       "California       119                  130              0.657   \n",
       "Colorado          11                  141              0.061   \n",
       "Kansas             1                  142              0.006   \n",
       "Nevada            17                  159              0.094   \n",
       "Oregon            11                  170              0.061   \n",
       "Utah               6                  176              0.033   \n",
       "Virginia           4                  180              0.022   \n",
       "Wyoming            1                  181              0.006   \n",
       "NaN               86                  nan                nan   \n",
       "\n",
       "           Cumulative Relative Freq. Relative Freq. [%] Cumulative Freq. [%]  \n",
       "State                                                                         \n",
       "Arizona                        0.061              6.077                6.077  \n",
       "California                     0.718             65.746               71.823  \n",
       "Colorado                       0.779              6.077               77.901  \n",
       "Kansas                         0.785              0.552               78.453  \n",
       "Nevada                         0.878              9.392               87.845  \n",
       "Oregon                         0.939              6.077               93.923  \n",
       "Utah                           0.972              3.315               97.238  \n",
       "Virginia                       0.994              2.210               99.448  \n",
       "Wyoming                        1.000              0.552              100.000  \n",
       "NaN                              nan                nan                  nan  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdt = get_fdt(df['State'], value_counts=True, fmt_values=True, dropna=False, na_position='first', na_aside_calc=True, order='ix_asc')\n",
    "fdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09719486",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_fdt() got an unexpected keyword argument 'na_aside'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# fdt_s1 = get_fdt(df['State'], value_counts=True, dropna=False, na_position='last', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=True)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# fdt_s1 = get_fdt(df['Country'], value_counts=True, dropna=False, na_position='last', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=True)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m fdt_g1 = \u001b[43mget_fdt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGender\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_pcts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_plain_relatives\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt_values\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdesc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_aside\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m fdt_g1\n",
      "\u001b[31mTypeError\u001b[39m: get_fdt() got an unexpected keyword argument 'na_aside'"
     ]
    }
   ],
   "source": [
    "# fdt_s1 = get_fdt(df['State'], value_counts=True, dropna=False, na_position='last', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=True)\n",
    "# fdt_s1 = get_fdt(df['Country'], value_counts=True, dropna=False, na_position='last', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=True)\n",
    "fdt_g1 = get_fdt(df['Gender'], value_counts=True, dropna=False, na_position='value', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=False)\n",
    "fdt_g1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33dc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdt_s1 = get_fdt(df['State'], value_counts=True, dropna=False, na_position='value', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=True)\n",
    "fdt_s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df['State'].value_counts(sort=False, dropna=True)\n",
    "fdt_vc = get_fdt(vc, dropna=True, na_position='value', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=True)\n",
    "fdt_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vc.dropna()\n",
    "# vc.drop(np.nan, errors='ignore')\n",
    "# # nans = vc[np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdt_vc1 = get_fdt(vc, value_counts=True, dropna=False, na_position='last', include_pcts=True, include_plain_relatives=True, fmt_values=True, order='desc', na_aside=True)\n",
    "# fdt_vc1 = get_fdt(vc, na_aside=False)\n",
    "fdt_vc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9dd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdt_s1 = get_fdt(df['Country'], value_counts=True, sort='asc', dropna=False, na_position='value', fmt_values=True, na_aside=False)\n",
    "# fdt_s1\n",
    "fdt_s2 = get_fdt(df['State'], value_counts=True, dropna=False, na_aside=False, na_position='value', fmt_values=True)\n",
    "fdt_s2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdt_2 = get_fdt(df['State'], value_counts=True)    \n",
    "cumulative_pcts = fdt_2['Cumulative Freq. [%]']\n",
    "top_3_pct = cumulative_pcts.iloc[min(2, len(cumulative_pcts)-1)]\n",
    "\n",
    "labels = [f\"{fdt_2.iloc[ix, 0]} ({fdt_2.iloc[ix, -2]:.1f} %)\" for ix in range(fdt_2.shape[0])]\n",
    "print(labels)\n",
    "\n",
    "for iloc_ix in range(len(cumulative_pcts)):\n",
    "    print(f\"cumulative_pcts.iloc[{iloc_ix}] = {cumulative_pcts.iloc[iloc_ix]}\")\n",
    "\n",
    "display(len(cumulative_pcts))\n",
    "display(top_3_pct)\n",
    "fdt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd06e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "822d6309",
   "metadata": {},
   "source": [
    "## Some Typing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f116700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional, Any, Literal, Sequence, TypeAlias\n",
    "import pandas as pd\n",
    "\n",
    "IndexElement: TypeAlias = Union[str, int, float, 'datetime.datetime']\n",
    "\n",
    "def to_series(\n",
    "    data: Union[pd.Series, np.ndarray, dict, list, set, pd.DataFrame],\n",
    "    index: Optional[Union[pd.Index, Sequence[IndexElement]]] = None,\n",
    "    name: Optional[str] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Converts input data into a pandas Series, optionally returning value counts.\n",
    "    \"\"\"\n",
    "    return pd.Series(data, index=index, name=name)\n",
    "\n",
    "\n",
    "to_series([1, 2, 3], ['a', 'b', 'c'], name='example_series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some Typing Tests\n",
    "## Standard Libs\n",
    "from typing import Union, Optional, Any, Literal, Sequence, TypeAlias\n",
    "\n",
    "# Third-Party Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter  # for pareto chart and ?\n",
    "import seaborn as sns\n",
    "## Claude - Qwen\n",
    "\n",
    "\n",
    "## Custom types for non-included typing annotations - Grok\n",
    "IndexElement: TypeAlias = Union[str, int, float, 'datetime.datetime', pd.Timestamp]\n",
    "\n",
    "\n",
    "def test_typing(\n",
    "        value: Union[int, float, str],\n",
    "        data: Optional[Union[pd.Index, Sequence[IndexElement]]] = None,\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Test function to demonstrate typing with Union.\n",
    "\n",
    "    Parameters:\n",
    "        value (Union[int, float, str]): The input value which can be an int, float, or str.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the input value.\n",
    "    \"\"\"\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"Numeric value: {value}\")\n",
    "    elif isinstance(value, str):\n",
    "        print(f\"String value: {value}\")\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported type: {type(value)}\")\n",
    "    \n",
    "    if data is not None:\n",
    "        if isinstance(data, pd.Index):\n",
    "            print(f\"Data is a pandas Index with {len(data)} elements.\")\n",
    "        elif isinstance(data, (list, tuple, np.ndarray)):\n",
    "            print(f\"Data is a sequence with {len(data)} elements.\")\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported data type: {type(data)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3da61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_typing(42, data=pd.Index(['a', 'b', 'c']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94091d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeAlias, Optional, Union, Sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "IndexElement: TypeAlias = Union[str, int, float, 'datetime.datetime', np.str_, np.int64, np.float64, np.datetime64]\n",
    "IndexLike: TypeAlias = Union[pd.Index, Sequence[IndexElement], NDArray[IndexElement]]\n",
    "\n",
    "def mi_funcion(data, index: Optional[IndexLike] = None) -> None:\n",
    "    if index is not None:\n",
    "        if isinstance(index, np.ndarray) and index.ndim != 1:\n",
    "            raise ValueError(\"El array de NumPy debe ser 1D para usarse como índice\")\n",
    "        index = pd.Index(index) if not isinstance(index, pd.Index) else index\n",
    "        print(\"Índice proporcionado:\", index)\n",
    "    else:\n",
    "        print(\"No se proporcionó índice, usando índice por defecto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76514e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_funcion(data=pd.Series([1, 2, 3]), index=np.array(['a', 'b', 'c']))\n",
    "mi_funcion(data=pd.Series([1, 2, 3]), index=pd.Index(['a', 'b', 'c']))\n",
    "mi_funcion(data=pd.Series([1, 2, 3]))  # Sin índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr5 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "\n",
    "sr5_ixname = sr5.index.name # if sr5.index.name else 'Index'\n",
    "# df5 = pd.DataFrame(sr5)\n",
    "# df5\n",
    "\n",
    "sr5.index.name\n",
    "sr5_ixname"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
